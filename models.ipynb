{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"IDS DATA\"\n",
    "\n",
    "uncorrected_audio_files = []\n",
    "allmfcc = []\n",
    "\n",
    "main = os.getcwd()\n",
    "\n",
    "os.chdir(file_name)\n",
    "Statements = os.listdir()\n",
    "idsfolder = os.getcwd()\n",
    "\n",
    "for x in Statements:\n",
    "    os.chdir(x)\n",
    "    templist = os.listdir()\n",
    "\n",
    "    for i in templist:\n",
    "\n",
    "        x , sr = librosa.load(i)\n",
    "            \n",
    "        MFCC_Features = librosa.feature.mfcc(y=x, sr=sr)\n",
    "        oned = MFCC_Features.flatten()\n",
    "\n",
    "        if len(oned) <= 5000 and len(oned) >= 1800:\n",
    "            oned = np.pad(oned,(0,5000-len(oned)),'constant')\n",
    "            allmfcc.append(oned)\n",
    "            uncorrected_audio_files.append(i[8:-4])\n",
    "    \n",
    "    os.chdir(idsfolder)\n",
    "\n",
    "os.chdir(main)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correcting File names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_names_corrected = []\n",
    "for j in uncorrected_audio_files:\n",
    "\n",
    "        tempstr = j.replace(\"AAHISTA\",\"AHISTA\").replace(\"KRO\",\"KARO\").replace(\"A C\",\"A.C\").replace(\"BND\",\"BAND\").replace(\"CHLAO\",\"CHALO\").replace('KAROO',\"KARO\").replace(\"TEEZ\",\"TEZ\").replace(\"TAIZ\",\"TEZ\").replace(\"TAEZ\",\"TEZ\").replace(\"GANA\",\"GAANA\").replace(\"AC\",\"A.C\").replace(\"AGALA.\",\"AGLA\")\n",
    "        tempstr = tempstr.replace(\"GANNA\",\"GAANA\").replace(\"AGLA.\",\"AGLA\").replace(\"LGAO\",\"LAGAO\").replace(\"AGLA.\",\"AGLA\").replace(\"CHANEL\",\"CHANNEL\").replace(\"KR0\",\"KARO\").replace(\"KRI\",\"KRO\").replace(\"JALAOO\",\"JALAO\").replace(\"BETHAQ\",\"BETHAK\").replace(\"BETHEK\",\"BETHAK\").replace(\"BYTHAK\",\"BETHAK\")\n",
    "        tempstr = tempstr.replace(\"BYTHAQ\",\"BETHAK\").replace(\"GANY\",\"GAANEY\").replace(\"GRAGE\",\"GARAGE\").replace(\"GARAGEKA\",\"GARAGE KA\").replace(\"GARRAGE\",\"GARAGE\").replace(\"AGLACHANNEL\",\"AGLA CHANNEL\").replace(\" WASHROOM\",\"WASHROOM\").replace(\" BATHROOM\",\"BATHROOM\").replace(\" GARAGE\",\"GARAGE\").replace(\" A.C\",\"A.C\").replace(\" KITCHEN\",\"KITCHEN\").replace(\" T.V\",\"T.V\").replace(\" PREVIOUS\",\"PREVIOUS\")\n",
    "        tempstr = tempstr.replace(\"CHALAOO\",\"CHALAO\").replace(\"KARO .\",\"KARO.\").replace(\"A.C.\",\"A.C\").replace(\" AGLACHANNAL\",\"AGLA CHANNEL\").replace(\" BEDROOM\",\"BEDROOM\")\n",
    "        tempstr = tempstr.replace(\"JALAO \",\"JALAO\").replace(\"KEO\",\"KARO\").replace(\"LAGAO \",\"LAGAO\").replace(\"ALGA\",\"AGLA\").replace(\"BEDROOM  KI LIGHT BAND KARO\",\"BEDROOM KI LIGHT BAND KARO\").replace(\"CHALAO\",\"CHALO\").replace(\" LOUNGE\",\"LOUNGE\").replace(\" PICHLA\",\"PICHLA\").replace(\" PICHLA.CHANNEL\",\"PICHLA CHANNEL\").replace(\" NEXT\",\"NEXT\").replace(\"CHANNAL\",\"CHANNEL\").replace(\" SONGS\",\"SONGS\")\n",
    "        tempstr = tempstr.replace(\"KARO  \",\"KARO\").replace(\"AWAZ\",\"AWAAZ\").replace(\"KY\",\"KI\").replace(\"TEIZ\",\"TEZ\").replace(\"LAGAO \",\"LAGAO\").replace(\"KMM\",\"KUM\").replace(\"KAM\",\"KUM\").replace(\"PR\",\"PAR\")\n",
    "        tempstr = tempstr.replace(\"SAMA\",\"SAMAA\").replace(\"WAHROOM\",\"WASHROOM\").replace(\"T.V.\",\"T.V\").replace(\"T.VV\",\"T.V\").replace(\" AGLA\",\"AGLA\")\n",
    "        tempstr = tempstr.replace(\" BETHAK\",\"BETHAK\").replace(\"KRO\",\"KARO\").replace(\" GAANEY\",\"GAANAY\").replace(\"GARAGE  KI LIGHT ON KARO\",\"GARAGE KI LIGHT ON KARO\").replace(\"PICHLA.CHANNEL\",\"PICHLA CHANNEL\").replace(\"PAREVIOUS\",\"PREVIOUS\").replace(\"PEECHLA\",\"PICHLA\").replace(\"LAGOA\",\"LAGAO\").replace(\"PEECHLA.CHANNEL\",\"PICHLA CHANNEL\")\n",
    "        tempstr = tempstr.replace(\"HUMT.V\",\"HUM TV\").replace(\"MASLAT.V\",\"MASLA T.V\").replace(\"KM\",\"KUM\").replace(\"OFF  \",\"OFF \").replace(\"KARO1\",\"KARO\").replace(\"BEHTAQ\",\"BEHTAK\").replace(\"BEHTHAK\",\"BEHTAK\").replace(\"GAANEY\",\"GAANAY\").replace(\"GAANE\",\"GAANAY\").replace(\"LAUNCH\",\"LOUNGE\").replace(\"PECHLA\",\"PICHLA\").replace(\"ZYADA\",\"ZIADA\").replace(\"ZIYADAH\",\"ZIADA\").replace(\"ZADA\",\"ZIADA\").replace(\"ZAIDA\",\"ZIADA\")\n",
    "        tempstr = tempstr.replace(\"AWAS\",\"AWAAZ\").replace(\"AWZ\",\"AWAAZ\").replace(\"LAR\",\"PAR\").replace(\"MASALAT.V\",\"MASLA T.V\").replace(\"SAMAAA\",\"SAMAA\").replace(\"TV\",\"T.V\").replace(\"WASHROOM KA\",\"WASHROOM KI\").replace(\"BLUB\",\"BULB\").replace(\"BULB IN\",\"BULB ON\").replace(\"BETHAK\",\"BEHTAK\").replace(\"KITCHEN KA \",\"KITCHEN KI \").replace(\"JAO\",\"JEO\").replace(\"WASHROOM KI\",\"WASHROOM KA\")\n",
    "        tempstr = tempstr.replace(\"BATHROOM KA LIGHT JALAO\",\"BATHROOM KI LIGHT JALAO\").replace(\"BEDROOM KA LIGHT JALAO\",\"BEDROOM KI LIGHT JALAO\").replace(\"BEHTAK KA LIGHT JALAO\",\"BEHTAK KI LIGHT JALAO\")\n",
    "        tempstr = tempstr.replace(\"KA LIGHT\",\"KI LIGHT\").replace(\"LAGAGO\",\"LAGAO\").replace(\"GEO\",\"JEO\").replace(\"UN MUTE\",\"UNMUTE\").replace(\"T.V PAR CARTOON LAGAO\",\"T.V PAR CARTOON NETWORK LAGAO\").replace(\"KARO \",\"KARO\").replace(\"KITCHEN KI BULB\",\"KITCHEN KA BULB\").replace(\"PICHLA.CHANNEL\",\"PICHLA CHANNEL\").replace(\"KARO'\",\"KARO\")\n",
    "\n",
    "        audio_file_names_corrected.append(tempstr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assiging Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_labels = []\n",
    "\n",
    "for i in audio_file_names_corrected:\n",
    "    if \"A.C\" in i:\n",
    "        all_files_labels.append(\"AC\")\n",
    "    \n",
    "    elif \"BULB\" in i or \"LIGHT\" in i:\n",
    "        all_files_labels.append(\"BULB\")\n",
    "    \n",
    "    elif \"GAANA\" in i or \"GAANAY\" in i or \"SONGS\" in i or \"SONG\" in i:\n",
    "        all_files_labels.append(\"GAANA\")\n",
    "\n",
    "    elif \"CHANNEL\" in i or \"T.V\" in i:\n",
    "        all_files_labels.append(\"TV\")\n",
    "\n",
    "d={'AC':0,'BULB':1, 'GAANA':2, 'TV':3 }\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Labels'] = all_files_labels\n",
    "df['Labels'] = df['Labels'].map(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Models\n",
    "https://machinelearningmastery.com/machine-learning-in-python-step-by-step/\n",
    "#ML Model code taken from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting Data\n",
    "\n",
    "X = np.array(allmfcc)\n",
    "y = df['Labels'].to_list()\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.1, random_state=20 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "pred=clf.predict(X_test)\n",
    "\n",
    "print (\"Accuracy:\" , accuracy_score(y_test,pred)*100)  \n",
    "print(\"F1 Score:\",f1_score(y_test, pred, average='macro')*100)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(\"Precision Score:\",precision_score(y_test,pred,average='macro')*100)\n",
    "print(\"Recall:\",recall_score(y_test,pred,average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "lr = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "pred=lr.predict(X_test)\n",
    "\n",
    "print (\"Accuracy:\" , accuracy_score(y_test,pred)*100)  \n",
    "print(\"F1 Score:\",f1_score(y_test, pred, average='macro')*100)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(\"Precision Score:\",precision_score(y_test,pred,average='macro')*100)\n",
    "print(\"Recall:\",recall_score(y_test,pred,average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BaggingClassifier https://scikit-learn.org/stable/modules/ensemble.html\n",
    "\n",
    "bagging = BaggingClassifier(KNeighborsClassifier(),max_samples=0.5, max_features=0.5)\n",
    "bagging.fit(X_train,y_train)\n",
    "pred=bagging.predict(X_test)\n",
    "\n",
    "print (\"Accuracy:\" , accuracy_score(y_test,pred)*100)  \n",
    "print(\"F1 Score:\",f1_score(y_test, pred, average='macro')*100)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(\"Precision Score:\",precision_score(y_test,pred,average='macro')*100)\n",
    "print(\"Recall:\",recall_score(y_test,pred,average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "print (\"Accuracy:\" , accuracy_score(y_test,pred)*100)  \n",
    "print(\"F1 Score:\",f1_score(y_test, pred, average='macro')*100)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(\"Precision Score:\",precision_score(y_test,pred,average='macro')*100)\n",
    "print(\"Recall:\",recall_score(y_test,pred,average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC\n",
    "svc = SVC(gamma='auto')\n",
    "svc.fit(X_train,y_train)\n",
    "pred = svc.predict(X_test)\n",
    "\n",
    "print (\"Accuracy:\" , accuracy_score(y_test,pred)*100)  \n",
    "print(\"F1 Score:\",f1_score(y_test, pred, average='macro')*100)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(\"Precision Score:\",precision_score(y_test,pred,average='macro')*100)\n",
    "print(\"Recall:\",recall_score(y_test,pred,average='macro')*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(clf,'CLF.pkl')\n",
    "joblib.dump(lr,'LR.pkl')\n",
    "joblib.dump(bagging,'BAG.pkl')\n",
    "joblib.dump(knn,'KNN.pkl')\n",
    "joblib.dump(svc,'SVC.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLF_from_joblib = joblib.load('CLF.pkl')\n",
    "LR_from_joblib = joblib.load('LR.pkl')\n",
    "BAG_from_joblib = joblib.load('BAG.pkl')\n",
    "KNN_from_joblib = joblib.load('KNN.pkl')\n",
    "SVC_from_joblib = joblib.load('SVC.pkl')\n",
    "\n",
    "pred = SVC_from_joblib.predict(X_test)\n",
    "print (\"Accuracy:\" , accuracy_score(y_test,pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLF:  TV\n",
      "LR:  TV\n",
      "BAG:  TV\n",
      "KNN:  Bulb\n",
      "SVC:  Bulb\n"
     ]
    }
   ],
   "source": [
    "def label(num):\n",
    "    if num == 0:\n",
    "        print(\"AC\")\n",
    "    elif num == 1:\n",
    "        print(\"Bulb\")\n",
    "    elif num == 2:\n",
    "        print(\"Gaana\")\n",
    "    elif num == 3:\n",
    "        print(\"TV\")\n",
    "\n",
    "\n",
    "CLF_from_joblib = joblib.load('CLF.pkl')\n",
    "LR_from_joblib = joblib.load('LR.pkl')\n",
    "BAG_from_joblib = joblib.load('BAG.pkl')\n",
    "KNN_from_joblib = joblib.load('KNN.pkl')\n",
    "SVC_from_joblib = joblib.load('SVC.pkl')\n",
    "\n",
    "x , sr = librosa.load(\"C:\\\\Users\\\\max55\\\\Downloads\\\\audio.wav\")\n",
    "            \n",
    "MFCC_Features = librosa.feature.mfcc(y=x, sr=sr)\n",
    "oned = MFCC_Features.flatten()\n",
    "\n",
    "if len(oned) <= 5000 and len(oned) >= 1800:\n",
    "    oned = np.pad(oned,(0,5000-len(oned)),'constant')\n",
    "\n",
    "    onedi = np.array(oned)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['MFCC'] = onedi\n",
    "\n",
    "\n",
    "pred = CLF_from_joblib.predict(df.T)\n",
    "print(\"CLF: \",end=\" \")\n",
    "label(pred)\n",
    "pred = LR_from_joblib.predict(df.T)\n",
    "print(\"LR: \",end=\" \")\n",
    "label(pred)\n",
    "pred = BAG_from_joblib.predict(df.T)\n",
    "print(\"BAG: \",end=\" \")\n",
    "label(pred)\n",
    "pred = KNN_from_joblib.predict(df.T)\n",
    "print(\"KNN: \",end=\" \")\n",
    "label(pred)\n",
    "pred = SVC_from_joblib.predict(df.T)\n",
    "print(\"SVC: \",end=\" \")\n",
    "label(pred)\n",
    "\n",
    "os.remove(\"C:\\\\Users\\\\max55\\\\Downloads\\\\audio.wav\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
